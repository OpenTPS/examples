{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Generate DRR and GTV Masks\nauthor: OpenTPS team\n\nThis example shows how to:\n- read model + ROI data from a serialized file\n- create a breathing signal using the motion amplitude present in the model\n- chose an ROI to apply the breathing signal to its center of mass\n-\n\n!!! does not work with public data for now since there is no struct in the public data !!!\n\nrunning time: ~ 10 minutes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the environment in google collab\n First you need to change the type of execution in the bottom left from processor to GPU. Then you can run the example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\nif \"google.colab\" in sys.modules:\n    from IPython import get_ipython\n    get_ipython().system('git clone https://gitlab.com/openmcsquare/opentps.git')\n    get_ipython().system('pip install ./opentps')\n    get_ipython().system('pip install scipy==1.10.1')\n    get_ipython().system('pip install cupy-cuda12x')\n    import opentps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom scipy.ndimage import zoom\nimport math\nimport time\nimport concurrent\nfrom itertools import repeat\nimport os\nimport sys\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import the needed opentps.core packages\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from opentps.core.processing.imageProcessing.resampler3D import crop3DDataAroundBox\nfrom opentps.core.io.serializedObjectIO import saveSerializedObjects, loadDataStructure\nfrom opentps.core.data.dynamicData._breathingSignals import SyntheticBreathingSignal\nfrom opentps.core.processing.deformableDataAugmentationToolBox.generateDynamicSequencesFromModel import generateDeformationListFromBreathingSignalsAndModel\nfrom opentps.core.processing.imageSimulation.DRRToolBox import forwardProjection\nfrom opentps.core.processing.imageProcessing.image2DManip import getBinaryMaskFromROIDRR, get2DMaskCenterOfMass\nfrom opentps.core.processing.imageProcessing.crop2D import getBoxAroundROI\nfrom opentps.core.processing.imageProcessing.imageTransform3D import getVoxelIndexFromPosition\nfrom opentps.core.processing.deformableDataAugmentationToolBox.modelManipFunctions import getAverageModelValuesAroundPosition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "paths selection\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "patientFolder = 'Patient_0'\npatientFolderComplement = ''\norgan = 'liver'\nbasePath = 'D:/ImageData/'\n\ndataSetFolder = '/test/'\ndataSetDataFolder = 'data/'\n\ndataPath = \"Path_to_your_serialized_patient_data/\"  # replace with the path to your serialized patient data\nsavingPath = \"Path_to_your_saving_path/\"  # replace with the path where you want to save the results\nif not os.path.exists(savingPath):\n    os.umask(0)\n    os.makedirs(savingPath)   # Create a new directory because it does not exist\n    os.makedirs(savingPath + dataSetDataFolder)  # Create a new directory because it does not exist\n    print(\"New directory created to save the data: \", savingPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "parameters selection\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sequenceDurationInSecs = 10\nsamplingFrequency = 4\nsubSequenceSize = 50\noutputSize = [64, 64]\nbodyContourToUse = 'body'\notherContourToUse = 'MidP CT GTV'\nmarginInMM = [50, 0, 100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "breathing signal parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "amplitude = 'model'\nvariationAmplitude = 2\nbreathingPeriod = 4\nvariationFrequency = 0.1\nshift = 2\nmeanNoise = 0\nvarianceNoise = 0.5\nsamplingPeriod = 1 / samplingFrequency\nsimulationTime = sequenceDurationInSecs\nmeanEvent = 2 / 30\n# use Z - 0 for Coronal and Z - 90 for sagittal\nprojAngle = 0\nprojAxis = 'Z'\n\nmultiprocessing = False\nmaxMultiProcUse = 4\ntryGPU = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function is specific to this example and used to :\n- deform a CTImage and an ROIMask,\n- create DRR's for both,\n- binarize the DRR of the ROIMask\n- compute its center of mass\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def deformImageAndMaskAndComputeDRRs(img, ROIMask, deformation, projectionAngle=0, projectionAxis='Z', tryGPU=True, outputSize=[]):\n    print('Start deformations and projections for deformation', deformation.name)\n    image = deformation.deformImage(img, fillValue='closest', outputType=np.int16, tryGPU=tryGPU)\n    # print(image.imageArray.shape, np.min(image.imageArray), np.max(image.imageArray), np.mean(image.imageArray))\n    mask = deformation.deformImage(ROIMask, fillValue='closest', outputType=np.int16, tryGPU=tryGPU)\n    centerOfMass3D = mask.centerOfMass\n\n    DRR = forwardProjection(image, projectionAngle, axis=projectionAxis)\n    DRRMask = forwardProjection(mask, projectionAngle, axis=projectionAxis)\n\n    halfDiff = int((DRR.shape[1] - image.gridSize[2])/2)           ## not sure this will work if orientation is changed\n    croppedDRR = DRR[:, halfDiff + 1:DRR.shape[1] - halfDiff - 1]         ## not sure this will work if orientation is changed\n    croppedDRRMask = DRRMask[:, halfDiff + 1:DRRMask.shape[1] - halfDiff - 1] ## not sure this will work if orientation is changed\n\n    if outputSize:\n        # print('Before resampling')\n        # print(croppedDRR.shape, np.min(croppedDRR), np.max(croppedDRR), np.mean(croppedDRR))\n        ratio = [outputSize[0]/croppedDRR.shape[0], outputSize[1]/croppedDRR.shape[1]]\n        croppedDRR = zoom(croppedDRR, ratio)\n        croppedDRRMask = zoom(croppedDRRMask, ratio)\n        # print('After resampling')\n        # print(croppedDRR.shape, np.min(croppedDRR), np.max(croppedDRR), np.mean(croppedDRR))\n\n    binaryDRRMask = getBinaryMaskFromROIDRR(croppedDRRMask)\n    centerOfMass = get2DMaskCenterOfMass(binaryDRRMask)\n    # print('CenterOfMass:', centerOfMass)\n\n    del image  # to release the RAM\n    del mask  # to release the RAM\n\n    print('Deformations and projections finished for deformation', deformation.name)\n\n    # plt.figure()\n    # plt.subplot(1, 5, 1)\n    # plt.imshow(DRR)\n    # plt.subplot(1, 5, 2)\n    # plt.imshow(croppedDRR)\n    # plt.subplot(1, 5, 3)\n    # plt.imshow(DRRMask)\n    # plt.subplot(1, 5, 4)\n    # plt.imshow(croppedDRRMask)\n    # plt.subplot(1, 5, 5)\n    # plt.imshow(binaryDRRMask)\n    # plt.show()\n\n    return [croppedDRR, binaryDRRMask, centerOfMass, centerOfMass3D]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load the patient data structure and get the model and RTStruct\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "patient = loadDataStructure(dataPath)[0]\ndynMod = patient.getPatientDataOfType(\"Dynamic3DModel\")[0]\nrtStruct = patient.getPatientDataOfType(\"RTStruct\")[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get the ROI and mask on which we want to apply the motion signal\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Available ROIs')\nrtStruct.print_ROINames()\n\ngtvContour = rtStruct.getContourByName(otherContourToUse)\nGTVMask = gtvContour.getBinaryMask(origin=dynMod.midp.origin, gridSize=dynMod.midp.gridSize, spacing=dynMod.midp.spacing)\ngtvBox = getBoxAroundROI(GTVMask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get the body contour to adjust the crop in the direction of the DRR projection\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bodyContour = rtStruct.getContourByName(bodyContourToUse)\nbodyMask = bodyContour.getBinaryMask(origin=dynMod.midp.origin, gridSize=dynMod.midp.gridSize, spacing=dynMod.midp.spacing)\nbodyBox = getBoxAroundROI(bodyMask)\n\nif projAngle == 0 and projAxis == 'Z': # coronal\n    croppingBox = [gtvBox[0], bodyBox[1], gtvBox[2]] ## create the used box combining the two boxes\nelif projAngle == 90 and projAxis == 'Z': # sagittal\n    croppingBox = [bodyBox[0], gtvBox[1], gtvBox[2]]\nelif projAngle == 0 and projAxis == 'X': # coronal\n    croppingBox = [gtvBox[0], bodyBox[1], gtvBox[2]]\nelif projAngle == 0 and projAxis == 'Y': # sagittal\n    croppingBox = [bodyBox[0], gtvBox[1], gtvBox[2]]\nelse:\n    print('Do not know how to handle crop in this axis/angle configuration, so the body is used')\n    croppingBox = [bodyBox[0], bodyBox[1], bodyBox[2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "crop the model data using the box\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crop3DDataAroundBox(dynMod, croppingBox, marginInMM=marginInMM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if you want to see the crop in the opentps_core you can save the data in cropped version\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "saveSerializedObjects(patient, savingPath + 'croppedModelAndROIs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get the 3D center of mass of this ROI\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gtvCenterOfMass = gtvContour.getCenterOfMass(dynMod.midp.origin, dynMod.midp.gridSize, dynMod.midp.spacing)\ngtvCenterOfMassInVoxels = getVoxelIndexFromPosition(gtvCenterOfMass, dynMod.midp)\nprint('Used ROI name', gtvContour.name)\nprint('Used ROI center of mass :', gtvCenterOfMass)\nprint('Used ROI center of mass in voxels:', gtvCenterOfMassInVoxels)\n\nif amplitude == 'model':\n    ## to get amplitude from model !!! it takes some time because 10 displacement fields must be computed just for this\n    modelValues = getAverageModelValuesAroundPosition(gtvCenterOfMass, dynMod, dimensionUsed='Z')\n    amplitude = np.max(modelValues) - np.min(modelValues)\n    print('Amplitude of deformation at ROI center of mass', amplitude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Signal creation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "newSignal = SyntheticBreathingSignal(amplitude=amplitude,\n                                        variationAmplitude=variationAmplitude,\n                                        breathingPeriod=breathingPeriod,\n                                        variationFrequency=variationFrequency,\n                                        shift=shift,\n                                        meanNoise=meanNoise,\n                                        varianceNoise=varianceNoise,\n                                        samplingPeriod=samplingPeriod,\n                                        simulationTime=sequenceDurationInSecs,\n                                        meanEvent=meanEvent)\n\nnewSignal.generate1DBreathingSignal()\n\npointList = [gtvCenterOfMass]\npointVoxelList = [gtvCenterOfMassInVoxels]\nsignalList = [newSignal]\n\nsaveSerializedObjects([signalList, pointList], savingPath + 'ROIsAndSignalObjects')\nfor signalIndex in range(len(signalList)):\n    signalList[signalIndex] = signalList[signalIndex].breathingSignal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "show signals and ROIs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prop_cycle = plt.rcParams['axes.prop_cycle']\ncolors = prop_cycle.by_key()['color']\nplt.figure(figsize=(12, 6))\nsignalAx = plt.subplot(2, 1, 2)\n\nfor pointIndex, point in enumerate(pointList):\n    ax = plt.subplot(2, 2 * len(pointList), 2 * pointIndex + 1)\n    ax.set_title('Slice Y:' + str(pointVoxelList[pointIndex][1]))\n    ax.imshow(np.rot90(dynMod.midp.imageArray[:, pointVoxelList[pointIndex][1], :]))\n    ax.scatter([pointVoxelList[pointIndex][0]], [dynMod.midp.imageArray.shape[2] - pointVoxelList[pointIndex][2]],\n                c=colors[pointIndex], marker=\"x\", s=100)\n    ax2 = plt.subplot(2, 2 * len(pointList), 2 * pointIndex + 2)\n    ax2.set_title('Slice Z:' + str(pointVoxelList[pointIndex][2]))\n    ax2.imshow(np.rot90(dynMod.midp.imageArray[:, :, pointVoxelList[pointIndex][2]]))\n    ax2.scatter([pointVoxelList[pointIndex][0]], [dynMod.midp.imageArray.shape[2] - pointVoxelList[pointIndex][2]],\n                c=colors[pointIndex], marker=\"x\", s=100)\n    signalAx.plot(newSignal.timestamps / 1000, signalList[pointIndex], c=colors[pointIndex])\n\nsignalAx.set_xlabel('Time (s)')\nsignalAx.set_ylabel('Deformation amplitude in Z direction (mm)')\nplt.savefig(savingPath + 'ROI_And_Signals_fig.pdf', dpi=300)\nplt.show()\n\n## -------------------------------------------------------------\n\nsequenceSize = newSignal.breathingSignal.shape[0]\nprint('Sequence Size =', sequenceSize, 'split by stack of ', subSequenceSize, '. Multiprocessing =', multiprocessing)\n\nsubSequencesIndexes = [subSequenceSize * i for i in range(math.ceil(sequenceSize/subSequenceSize))]\nsubSequencesIndexes.append(sequenceSize)\nprint('Sub sequences indexes', subSequencesIndexes)\n\nstartTime = time.time()\n\nif multiprocessing == False:\n\n    resultList = []\n\n    for i in range(len(subSequencesIndexes)-1):\n        print('Creating deformations for images', subSequencesIndexes[i], 'to', subSequencesIndexes[i + 1] - 1)\n\n        deformationList = generateDeformationListFromBreathingSignalsAndModel(dynMod,\n                                                                                signalList,\n                                                                                pointList,\n                                                                                signalIdxUsed=[subSequencesIndexes[i], subSequencesIndexes[i+1]],\n                                                                                dimensionUsed='Z',\n                                                                                outputType=np.float32)\n\n        for deformationIndex, deformation in enumerate(deformationList):\n            resultList.append(deformImageAndMaskAndComputeDRRs(dynMod.midp,\n                                                                GTVMask,\n                                                                deformation,\n                                                                projectionAngle=projAngle,\n                                                                projectionAxis=projAxis,\n                                                                outputSize=outputSize,\n                                                                tryGPU=True))\n\n\n    savingPath += dataSetDataFolder + f'Patient_0_{sequenceSize}_DRRMasksAndCOM'\n    saveSerializedObjects(resultList, savingPath + str(sequenceSize))\n\n\nelif multiprocessing == True:\n\n    resultList = []\n\n    if subSequenceSize > maxMultiProcUse:  ## re-adjust the subSequenceSize since this will be done in multi processing\n        subSequenceSize = maxMultiProcUse\n        print('SubSequenceSize put to', maxMultiProcUse, 'for multiprocessing.')\n        print('Sequence Size =', sequenceSize, 'split by stack of ', subSequenceSize, '. Multiprocessing =', multiprocessing)\n        subSequencesIndexes = [subSequenceSize * i for i in range(math.ceil(sequenceSize / subSequenceSize))]\n        subSequencesIndexes.append(sequenceSize)\n\n    for i in range(len(subSequencesIndexes)-1):\n        print('Creating deformations for images', subSequencesIndexes[i], 'to', subSequencesIndexes[i + 1] - 1)\n\n        deformationList = generateDeformationListFromBreathingSignalsAndModel(dynMod,\n                                                                                signalList,\n                                                                                pointList,\n                                                                                signalIdxUsed=[subSequencesIndexes[i], subSequencesIndexes[i+1]],\n                                                                                dimensionUsed='Z',\n                                                                                outputType=np.float32)\n\n        print('Start multi process deformation with', len(deformationList), 'deformations')\n        with concurrent.futures.ProcessPoolExecutor() as executor:\n\n            results = executor.map(deformImageAndMaskAndComputeDRRs, repeat(dynMod.midp), repeat(GTVMask), deformationList, repeat(projAngle), repeat(projAxis), repeat(tryGPU), repeat(outputSize))\n            resultList += results\n\n        print('ResultList lenght', len(resultList))\n\n    savingPath += dataSetDataFolder + f'Patient_0_{sequenceSize}_DRRMasksAndCOM_multiProcTest'\n    saveSerializedObjects(resultList, savingPath)\n\nstopTime = time.time()\nprint('Test with multiprocessing =', multiprocessing, '. Sub-sequence size:', str(subSequenceSize), 'finished in', np.round(stopTime - startTime, 2) / 60, 'minutes')\nprint(np.round((stopTime - startTime)/len(resultList), 2), 'sec per sample')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}